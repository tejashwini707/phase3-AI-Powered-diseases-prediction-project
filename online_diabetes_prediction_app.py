# -*- coding: utf-8 -*-
"""online diabetes_prediction_app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pHviLF4lZZdTRzcdaG0xrZgUSunJRSoK
"""

# Step 1: Install dependencies
!pip install scikit-learn pandas

# Step 2: Import libraries
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
import joblib
# Try importing files if available, otherwise provide alternative
try:
    from google.colab import files  # Import for Google Colab
except ImportError:
    files = None  # Set to None if not in Google Colab
    print("Warning: 'files' object not available. File upload functionality may not work.")

# Step 3: Load dataset and train model
url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'
columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',
           'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']
df = pd.read_csv(url, names=columns)

X = df.drop('Outcome', axis=1)
y = df['Outcome']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier()
model.fit(X_train, y_train)

# Step 4: Evaluate model
accuracy = accuracy_score(y_test, model.predict(X_test))
print(f"Model Accuracy: {accuracy * 100:.2f}%")

# Add these lines at the beginning if the file is missing

# Step 5: Save model again in case it's missing
# (This will retrain the model if the file isn't found)
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import joblib

url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'
columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',
           'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']
df = pd.read_csv(url, names=columns)

X = df.drop('Outcome', axis=1)
y = df['Outcome']
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = RandomForestClassifier()
model.fit(X_train, y_train)

joblib.dump(model, 'diabetes_model.pkl')

# Step 7: Load uploaded file

# Check if 'files' is available (e.g., in Google Colab)
if files is not None:
    uploaded = files.upload()  # Get uploaded files if available

    for filename in uploaded.keys():
        user_df = pd.read_csv(filename)
        print(f"\nUploaded Data Preview:\n{user_df.head()}")
else:
    print("File upload is not supported in this environment.")
    # Provide alternative way to load data (e.g., specify a local file path)
    # user_df = pd.read_csv('your_local_file_path.csv')

# Step 8: Load model and predict
model = joblib.load('diabetes_model.pkl')
# Drop the 'Outcome' column from user_df before prediction
predictions = model.predict(user_df.drop('Outcome', axis=1))

#Step 9: Show results
user_df['DiabetesPrediction'] = ['Likely Diabetic' if p == 1 else 'Unlikely Diabetic' for p in predictions]
print("\nPrediction Results:\n")
print(user_df[['DiabetesPrediction']])

# Optional: Download results
user_df.to_csv("prediction_results.csv", index=False)
files.download("prediction_results.csv")

import matplotlib.pyplot as plt
import pandas as pd

# Step 1: Reload the dataframe (df)
url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'
columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',
           'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']
df = pd.read_csv(url, names=columns)

# Step 2: Now create the histograms
df.hist(figsize=(12, 10))
plt.suptitle("Feature Distributions", fontsize=16)
plt.tight_layout()
plt.show()

import seaborn as sns

# Create box plots for features grouped by outcome
plt.figure(figsize=(12, 6))
sns.boxplot(x="Outcome", y="Glucose", data=df)
plt.title("Glucose Levels by Outcome", fontsize=14)
plt.show()

plt.figure(figsize=(8, 6))
plt.scatter(df["Glucose"], df["BMI"], c=df["Outcome"], cmap="viridis")
plt.xlabel("Glucose")
plt.ylabel("BMI")
plt.title("Glucose vs. BMI", fontsize=14)
plt.colorbar(label="Outcome")
plt.show()

import seaborn as sns

correlation_matrix = df.corr()
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm")
plt.title("Correlation Matrix", fontsize=16)
plt.show()

from sklearn.metrics import f1_score
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
import joblib # Make sure joblib is imported

# Step 1: Reload the dataframe (if needed) and train model
# (This assumes you've run the cell that loaded and trained the model previously)
# Otherwise, you need to reload your dataset and train your model again here:
# url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'
# ... (load and train the model as in your original code) ...

try:
    model = joblib.load('diabetes_model.pkl')  # Attempt to load existing model
except FileNotFoundError:
    print("Model file not found. Please re-train the model.")
    # Add code to load dataset and train the model
    # This prevents crashes if the model file is missing
    url = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv'
    columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',
               'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']
    df = pd.read_csv(url, names=columns)
    X = df.drop('Outcome', axis=1)
    y = df['Outcome']
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model = RandomForestClassifier()
    model.fit(X_train, y_train)

# Generate predictions using the model
predictions = model.predict(X_test)

# Now calculate the F1 score
f1 = f1_score(y_test, predictions)
print(f"\n{'F1 Score:':<15} {f1:.2f}")

# prompt: code for confusion matrix

from sklearn.metrics import confusion_matrix
import seaborn as sns

# Assuming 'y_test' and 'predictions' are defined from previous code

cm = confusion_matrix(y_test, predictions)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues",
            xticklabels=['Predicted 0', 'Predicted 1'],
            yticklabels=['Actual 0', 'Actual 1'])
plt.title("Confusion Matrix", fontsize=14)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

!pip install gradio
import gradio as gr
import pandas as pd
import joblib

# Load the trained model
model = joblib.load('diabetes_model.pkl')

# Define the prediction function
def predict_diabetes(Pregnancies, Glucose, BloodPressure, SkinThickness, Insulin, BMI, DiabetesPedigreeFunction, Age):
    user_data = pd.DataFrame({
        'Pregnancies': [Pregnancies],
        'Glucose': [Glucose],
        'BloodPressure': [BloodPressure],
        'SkinThickness': [SkinThickness],
        'Insulin': [Insulin],
        'BMI': [BMI],
        'DiabetesPedigreeFunction': [DiabetesPedigreeFunction],
        'Age': [Age]
    })
    prediction = model.predict(user_data)[0]
    return "Likely Diabetic" if prediction == 1 else "Unlikely Diabetic"

# Create the Gradio interface
iface = gr.Interface(
    fn=predict_diabetes,
    inputs=[
        gr.Number(label="Pregnancies"),
        gr.Number(label="Glucose"),
        gr.Number(label="Blood Pressure"),
        gr.Number(label="Skin Thickness"),
        gr.Number(label="Insulin"),
        gr.Number(label="BMI"),
        gr.Number(label="Diabetes Pedigree Function"),
        gr.Number(label="Age")
    ],
    outputs="text",
    title="Diabetes Prediction App"
)

# Launch the interface
iface.launch()